# MMSA é¡¹ç›®è®­ç»ƒæµ‹è¯•æµç¨‹è¯´æ˜

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

MMSA (Multimodal Sentiment Analysis) æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†ææ¡†æ¶ï¼Œæ”¯æŒï¼š
- **15+ ç§æ¨¡å‹**ï¼šTFN, LMF, MFN, MulT, MISA, Self-MM, ALMTç­‰
- **3 ç§æ•°æ®é›†**ï¼šMOSI, MOSEI, CH-SIMS
- **è‡ªå®šä¹‰æ•°æ®é›†**ï¼šæ”¯æŒé€šè¿‡æ•°æ®è½¬æ¢è„šæœ¬æ·»åŠ æ–°æ•°æ®é›†

---

## ğŸ”„ å®Œæ•´æµç¨‹æ¦‚è§ˆ

```
æ•°æ®å‡†å¤‡ â†’ æ•°æ®è½¬æ¢ â†’ é…ç½®è®¾ç½® â†’ æ¨¡å‹è®­ç»ƒ â†’ æ¨¡å‹æµ‹è¯• â†’ ç»“æœè¯„ä¼°
```

---

## 1ï¸âƒ£ æ•°æ®å‡†å¤‡é˜¶æ®µ

### 1.1 åŸå§‹æ•°æ®æ ¼å¼
åŸå§‹æ•°æ®é€šå¸¸æ˜¯ä¸€ä¸ªåŒ…å«æ ·æœ¬çš„åˆ—è¡¨ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«ï¼š
- `text`: æ–‡æœ¬ç‰¹å¾ï¼ˆ768ç»´BERTå‘é‡æˆ–åºåˆ—ï¼‰
- `audio`: éŸ³é¢‘æ³¢å½¢æˆ–ç‰¹å¾
- `vision`: è§†è§‰ç‰¹å¾
- `label`: æ ‡ç­¾ï¼ˆ0.0/1.0 æˆ–å›å½’å€¼ï¼‰

### 1.2 æ•°æ®è½¬æ¢ (`convert_train_data.py`)
å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºMMSAæ¡†æ¶æœŸæœ›çš„æ ¼å¼ï¼š

```python
# è½¬æ¢è„šæœ¬åŠŸèƒ½ï¼š
1. æ–‡æœ¬ç‰¹å¾è½¬æ¢ï¼š768ç»´å‘é‡ â†’ text_bertæ ¼å¼ [3, seq_len] æˆ–åºåˆ—æ ¼å¼ [seq_len, 768]
2. éŸ³é¢‘ç‰¹å¾æå–ï¼šæ³¢å½¢ â†’ MFCCç‰¹å¾åºåˆ— [seq_len, 13]
3. è§†è§‰ç‰¹å¾å¤„ç†ï¼švideo_feature â†’ vision [seq_len, dim]
4. æ ‡ç­¾æ ¼å¼è½¬æ¢ï¼š0.0/1.0 â†’ regression_labels (æµ®ç‚¹æ•°)
5. æ•°æ®é›†åˆ’åˆ†ï¼štrain/valid/test (70%/15%/15%)
6. åºåˆ—å¯¹é½ï¼šå¡«å……åˆ°æœ€å¤§é•¿åº¦
```

**è¾“å‡ºæ ¼å¼**ï¼š
```python
{
    "train": {
        "text": [],              # æˆ– text_bert
        "audio": [],
        "vision": [],
        "id": [],
        "regression_labels": [],
        "audio_lengths": [],
        "vision_lengths": []
    },
    "valid": {...},
    "test": {...}
}
```

---

## 2ï¸âƒ£ é…ç½®è®¾ç½®é˜¶æ®µ

### 2.1 é…ç½®æ–‡ä»¶ä½ç½®
- **å›å½’ä»»åŠ¡é…ç½®**ï¼š`src/MMSA/config/config_regression.json`
- **è¶…å‚æ•°è°ƒä¼˜é…ç½®**ï¼š`src/MMSA/config/config_tune.json`

### 2.2 å…³é”®é…ç½®å‚æ•°
```json
{
    "model_name": "tfn",           // æ¨¡å‹åç§°
    "dataset_name": "custom",      // æ•°æ®é›†åç§°
    "featurePath": "path/to/data.pkl",  // ç‰¹å¾æ–‡ä»¶è·¯å¾„
    "batch_size": 32,              // æ‰¹æ¬¡å¤§å°
    "learning_rate": 0.001,        // å­¦ä¹ ç‡
    "early_stop": 20,              // æ—©åœè½®æ•°
    "KeyEval": "MAE",              // ä¸»è¦è¯„ä¼°æŒ‡æ ‡
    "feature_dims": [768, 13, 768], // [æ–‡æœ¬, éŸ³é¢‘, è§†è§‰]ç‰¹å¾ç»´åº¦
    "seq_lens": [50, 512, 197]     // [æ–‡æœ¬, éŸ³é¢‘, è§†è§‰]åºåˆ—é•¿åº¦
}
```

---

## 3ï¸âƒ£ è®­ç»ƒæµç¨‹ (`run.py` â†’ `_run()`)

### 3.1 å…¥å£å‡½æ•°
```python
MMSA_run(
    model_name='tfn',
    dataset_name='custom',
    seeds=[1111],
    gpu_ids=[0],
    config=config_dict
)
```

### 3.2 è®­ç»ƒæ­¥éª¤è¯¦è§£

#### æ­¥éª¤1ï¼šåˆå§‹åŒ–
```python
# 1. åŠ è½½é…ç½®
args = get_config_regression(model_name, dataset_name, config_file)
args['device'] = assign_gpu(gpu_ids)  # åˆ†é…GPU
args['model_save_path'] = Path(...)   # æ¨¡å‹ä¿å­˜è·¯å¾„

# 2. è®¾ç½®éšæœºç§å­
setup_seed(seed)
```

#### æ­¥éª¤2ï¼šæ•°æ®åŠ è½½ (`data_loader.py`)
```python
# åˆ›å»ºæ•°æ®åŠ è½½å™¨
dataloader = MMDataLoader(args, num_workers=4)

# æ•°æ®åŠ è½½å™¨åŒ…å«ï¼š
# - dataloader['train']: è®­ç»ƒé›†
# - dataloader['valid']: éªŒè¯é›†
# - dataloader['test']: æµ‹è¯•é›†
```

**æ•°æ®åŠ è½½è¿‡ç¨‹**ï¼š
1. ä»pickleæ–‡ä»¶åŠ è½½æ•°æ®
2. æ ¹æ®`use_bert`é€‰æ‹©æ–‡æœ¬ç‰¹å¾æ ¼å¼
3. å¤„ç†åºåˆ—é•¿åº¦ä¿¡æ¯ï¼ˆunalignedæ•°æ®ï¼‰
4. å¤„ç†ç¼ºå¤±å€¼ï¼ˆ-inf â†’ 0ï¼‰
5. å½’ä¸€åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰

#### æ­¥éª¤3ï¼šæ¨¡å‹åˆå§‹åŒ–
```python
# åˆ›å»ºæ¨¡å‹
model = AMIO(args).to(args['device'])

# AMIO (All Models in One) æ ¹æ®model_nameè‡ªåŠ¨é€‰æ‹©å¯¹åº”æ¨¡å‹
# æ”¯æŒçš„æ¨¡å‹åœ¨ models/ ç›®å½•ä¸‹ï¼š
# - singleTask/: TFN, LMF, MFN, MulT, MISAç­‰
# - multiTask/: MTFN, MLMF, Self-MMç­‰
```

#### æ­¥éª¤4ï¼šè®­ç»ƒå™¨åˆå§‹åŒ–
```python
# è·å–å¯¹åº”çš„è®­ç»ƒå™¨
trainer = ATIO().getTrain(args)

# ATIO (All Trains in One) æ ¹æ®model_nameé€‰æ‹©è®­ç»ƒå™¨
# è®­ç»ƒå™¨åœ¨ trains/ ç›®å½•ä¸‹ï¼Œæ¯ä¸ªæ¨¡å‹æœ‰å¯¹åº”çš„è®­ç»ƒç±»
```

#### æ­¥éª¤5ï¼šè®­ç»ƒå¾ªç¯ (`trainer.do_train()`)

```python
# ä¼ªä»£ç æµç¨‹
while True:  # ç›´åˆ°æ—©åœ
    epochs += 1
    
    # === è®­ç»ƒé˜¶æ®µ ===
    model.train()
    for batch in dataloader['train']:
        # 1. å‰å‘ä¼ æ’­
        outputs = model(text, audio, vision)
        
        # 2. è®¡ç®—æŸå¤±
        loss = criterion(outputs['M'], labels)
        
        # 3. åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        # 4. æ”¶é›†é¢„æµ‹å’ŒçœŸå®å€¼
        y_pred.append(outputs['M'])
        y_true.append(labels)
    
    # 5. è®¡ç®—è®­ç»ƒæŒ‡æ ‡
    train_results = metrics(y_pred, y_true)
    
    # === éªŒè¯é˜¶æ®µ ===
    val_results = trainer.do_test(model, dataloader['valid'], mode="VAL")
    
    # === ä¿å­˜æœ€ä½³æ¨¡å‹ ===
    if val_results[KeyEval] ä¼˜äº best_valid:
        best_valid = val_results[KeyEval]
        best_epoch = epochs
        torch.save(model.state_dict(), model_save_path)
    
    # === æ—©åœæ£€æŸ¥ ===
    if epochs - best_epoch >= early_stop:
        break
```

**å…³é”®æŒ‡æ ‡**ï¼š
- `KeyEval`: ä¸»è¦è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚MAE, Corrç­‰ï¼‰
- `min_or_max`: åˆ¤æ–­æŒ‡æ ‡æ˜¯è¶Šå°è¶Šå¥½è¿˜æ˜¯è¶Šå¤§è¶Šå¥½
- `early_stop`: éªŒè¯é›†æ€§èƒ½ä¸å†æå‡çš„è½®æ•°

---

## 4ï¸âƒ£ æµ‹è¯•æµç¨‹ (`trainer.do_test()`)

### 4.1 æµ‹è¯•æ­¥éª¤

```python
# 1. åŠ è½½æœ€ä½³æ¨¡å‹
model.load_state_dict(torch.load(model_save_path))
model.eval()

# 2. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
test_results = trainer.do_test(model, dataloader['test'], mode="TEST")
```

### 4.2 æµ‹è¯•è¿‡ç¨‹ (`TFN.py` ç¤ºä¾‹)

```python
def do_test(self, model, dataloader, mode="TEST"):
    model.eval()
    y_pred, y_true = []
    
    with torch.no_grad():
        for batch in dataloader:
            # å‰å‘ä¼ æ’­ï¼ˆä¸è®¡ç®—æ¢¯åº¦ï¼‰
            outputs = model(text, audio, vision)
            
            # æ”¶é›†é¢„æµ‹å’ŒçœŸå®å€¼
            y_pred.append(outputs['M'].cpu())
            y_true.append(labels.cpu())
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    eval_results = metrics(y_pred, y_true)
    
    # å¦‚æœæ˜¯customæ•°æ®é›†ï¼Œæ·»åŠ COPAè¯„ä¼°
    if dataset_name == 'custom':
        copa_results = eval_copa_paradigm_accuracy(...)
        eval_results.update(copa_results)
    
    return eval_results
```

### 4.3 è¯„ä¼°æŒ‡æ ‡ (`metricsTop.py`)

**å›å½’ä»»åŠ¡æŒ‡æ ‡**ï¼š
- `MAE`: å¹³å‡ç»å¯¹è¯¯å·®
- `Corr`: ç›¸å…³ç³»æ•°
- `Mult_acc_7`: 7çº§å¤šåˆ†ç±»å‡†ç¡®ç‡
- `Mult_acc_5`: 5çº§å¤šåˆ†ç±»å‡†ç¡®ç‡
- `Mult_acc_3`: 3çº§å¤šåˆ†ç±»å‡†ç¡®ç‡
- `Non0_acc_2`: ä¸åŒ…å«0çš„äºŒåˆ†ç±»å‡†ç¡®ç‡
- `Non0_F1_score`: ä¸åŒ…å«0çš„F1åˆ†æ•°
- `Has0_acc_2`: åŒ…å«0çš„äºŒåˆ†ç±»å‡†ç¡®ç‡
- `Has0_F1_score`: åŒ…å«0çš„F1åˆ†æ•°

**åˆ†ç±»ä»»åŠ¡æŒ‡æ ‡**ï¼š
- `Acc_3`: ä¸‰åˆ†ç±»å‡†ç¡®ç‡
- `F1_score_3`: ä¸‰åˆ†ç±»F1åˆ†æ•°
- `Has0_acc_2`: åŒ…å«0çš„äºŒåˆ†ç±»å‡†ç¡®ç‡
- `Non0_acc_2`: ä¸åŒ…å«0çš„äºŒåˆ†ç±»å‡†ç¡®ç‡

**COPAè¯„ä¼°**ï¼ˆè‡ªå®šä¹‰æ•°æ®é›†ï¼‰ï¼š
- `COPA_overall_acc`: æ•´ä½“å‡†ç¡®ç‡
- `COPA_P1_acc` ~ `COPA_P12_acc`: å„èŒƒå¼å‡†ç¡®ç‡

---

## 5ï¸âƒ£ ç»“æœä¿å­˜

### 5.1 æ¨¡å‹ä¿å­˜
```python
# ä¿å­˜ä½ç½®
model_save_path = model_save_dir / f"{model_name}-{dataset_name}.pth"

# ä¿å­˜å†…å®¹
torch.save(model.state_dict(), model_save_path)
```

### 5.2 ç»“æœä¿å­˜
```python
# ä¿å­˜ä½ç½®
csv_file = res_save_dir / "normal" / f"{dataset_name}.csv"

# ä¿å­˜å†…å®¹ï¼ˆCSVæ ¼å¼ï¼‰
# åŒ…å«å¤šä¸ªéšæœºç§å­çš„å¹³å‡ç»“æœ
# åˆ—ï¼šModel, MAE, Corr, Non0_acc_2, Non0_F1_score, ...
```

### 5.3 æ—¥å¿—ä¿å­˜
```python
# ä¿å­˜ä½ç½®
log_file = log_dir / f"{model_name}-{dataset_name}.log"

# åŒ…å«ï¼š
# - è®­ç»ƒè¿‡ç¨‹æ—¥å¿—
# - æ¯ä¸ªepochçš„è®­ç»ƒ/éªŒè¯æŒ‡æ ‡
# - æœ€ç»ˆæµ‹è¯•ç»“æœ
```

---

## 6ï¸âƒ£ ä½¿ç”¨ç¤ºä¾‹

### 6.1 Python API æ–¹å¼

```python
from MMSA.run import MMSA_run

# åŸºæœ¬ä½¿ç”¨
results = MMSA_run(
    model_name='tfn',
    dataset_name='custom',
    seeds=[1111, 1112, 1113],
    gpu_ids=[0],
    num_workers=4
)

# è‡ªå®šä¹‰é…ç½®
config = {
    'batch_size': 16,
    'learning_rate': 0.0005,
    'early_stop': 15
}
results = MMSA_run(
    model_name='tfn',
    dataset_name='custom',
    config=config,
    seeds=[1111]
)
```

### 6.2 å‘½ä»¤è¡Œæ–¹å¼

```bash
# åŸºæœ¬ä½¿ç”¨
python -m MMSA -d custom -m tfn -s 1111 -s 1112

# æŒ‡å®šGPU
python -m MMSA -d custom -m tfn -s 1111 --gpu-ids 0

# è¶…å‚æ•°è°ƒä¼˜
python -m MMSA -d custom -m tfn -t -tt 50
```

### 6.3 è‡ªå®šä¹‰è®­ç»ƒè„šæœ¬

é¡¹ç›®æä¾›äº†ä¸‰ä¸ªè®­ç»ƒè„šæœ¬ï¼š
- `train_gpu.py`: GPUè®­ç»ƒè„šæœ¬
- `train_cpu.py`: CPUè®­ç»ƒè„šæœ¬
- `train_custom.py`: è‡ªå®šä¹‰è®­ç»ƒè„šæœ¬

**ç¤ºä¾‹** (`train_gpu.py`):
```python
from MMSA.run import MMSA_run

results = MMSA_run(
    model_name='tfn',
    dataset_name='custom',
    seeds=[1111],
    gpu_ids=[0],
    num_workers=4,
    model_save_dir="./saved_models",
    res_save_dir="./results",
    log_dir="./logs"
)
```

---

## 7ï¸âƒ£ æ•°æ®æµå›¾

```
åŸå§‹æ•°æ® (train_12.16_1.pkl)
    â†“
[convert_train_data.py]
    â†“
è½¬æ¢åæ•°æ® (train_12.16_1_converted.pkl)
    â†“
[MMDataLoader]
    â†“
DataLoader (train/valid/test)
    â†“
[AMIO Model]
    â†“
æ¨¡å‹è¾“å‡º (predictions)
    â†“
[MetricsTop]
    â†“
è¯„ä¼°ç»“æœ (MAE, Corr, Acc, ...)
    â†“
[CSV/Logä¿å­˜]
```

---

## 8ï¸âƒ£ å…³é”®æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | åŠŸèƒ½ |
|------|------|
| `run.py` | ä¸»è¿è¡Œå…¥å£ï¼ŒåŒ…å«`MMSA_run()`å‡½æ•° |
| `data_loader.py` | æ•°æ®åŠ è½½å™¨ï¼Œå¤„ç†ä¸åŒæ•°æ®é›†æ ¼å¼ |
| `config.py` | é…ç½®åŠ è½½å‡½æ•° |
| `trains/ATIO.py` | è®­ç»ƒå™¨å·¥å‚ï¼Œæ ¹æ®æ¨¡å‹åé€‰æ‹©è®­ç»ƒå™¨ |
| `trains/singleTask/TFN.py` | TFNæ¨¡å‹è®­ç»ƒå™¨å®ç° |
| `utils/metricsTop.py` | è¯„ä¼°æŒ‡æ ‡è®¡ç®— |
| `models/AMIO.py` | æ¨¡å‹å·¥å‚ï¼Œæ ¹æ®æ¨¡å‹åé€‰æ‹©æ¨¡å‹ |
| `convert_train_data.py` | æ•°æ®è½¬æ¢è„šæœ¬ |

---

## 9ï¸âƒ£ å¤šéšæœºç§å­è¿è¡Œ

æ¡†æ¶æ”¯æŒä½¿ç”¨å¤šä¸ªéšæœºç§å­è¿è¡Œï¼Œæœ€ç»ˆç»“æœå–å¹³å‡å€¼ï¼š

```python
seeds = [1111, 1112, 1113, 1114, 1115]

for seed in seeds:
    setup_seed(seed)
    result = _run(args, num_workers)
    model_results.append(result)

# è®¡ç®—å¹³å‡å€¼
final_results = {
    metric: np.mean([r[metric] for r in model_results])
    for metric in metrics
}
```

---

## ğŸ”Ÿ è¶…å‚æ•°è°ƒä¼˜æ¨¡å¼

```python
MMSA_run(
    model_name='tfn',
    dataset_name='custom',
    is_tune=True,        # å¼€å¯è°ƒä¼˜æ¨¡å¼
    tune_times=50,       # è°ƒä¼˜æ¬¡æ•°
    seeds=[1111]
)
```

**è°ƒä¼˜æµç¨‹**ï¼š
1. ä»`config_tune.json`åŠ è½½è¶…å‚æ•°èŒƒå›´
2. éšæœºé€‰æ‹©ä¸€ç»„è¶…å‚æ•°
3. è®­ç»ƒæ¨¡å‹
4. åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
5. ä¿å­˜ç»“æœåˆ°CSV
6. é‡å¤50æ¬¡
7. é€‰æ‹©æœ€ä½³è¶…å‚æ•°ç»„åˆ

---

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **æ•°æ®æ ¼å¼**ï¼šç¡®ä¿è½¬æ¢åçš„æ•°æ®æ ¼å¼ç¬¦åˆMMSAè¦æ±‚
2. **ç‰¹å¾ç»´åº¦**ï¼šæ£€æŸ¥`feature_dims`å’Œ`seq_lens`é…ç½®æ˜¯å¦æ­£ç¡®
3. **GPUå†…å­˜**ï¼šæ ¹æ®GPUå†…å­˜è°ƒæ•´`batch_size`
4. **æ—©åœæœºåˆ¶**ï¼šåˆç†è®¾ç½®`early_stop`é¿å…è¿‡æ‹Ÿåˆ
5. **éšæœºç§å­**ï¼šä½¿ç”¨å¤šä¸ªéšæœºç§å­è·å¾—æ›´ç¨³å®šçš„ç»“æœ
6. **æ—¥å¿—æŸ¥çœ‹**ï¼šè®­ç»ƒè¿‡ç¨‹ä¼šè¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶ï¼Œä¾¿äºè°ƒè¯•

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹

1. **å‡†å¤‡æ•°æ®**ï¼šè¿è¡Œ`convert_train_data.py`è½¬æ¢æ•°æ®
2. **é…ç½®å‚æ•°**ï¼šä¿®æ”¹`config_regression.json`ä¸­çš„æ•°æ®é›†é…ç½®
3. **è¿è¡Œè®­ç»ƒ**ï¼šæ‰§è¡Œ`python train_gpu.py`æˆ–ä½¿ç”¨API
4. **æŸ¥çœ‹ç»“æœ**ï¼šæ£€æŸ¥`results/normal/custom.csv`å’Œæ—¥å¿—æ–‡ä»¶

---

**æœ€åæ›´æ–°**: 2025-01-03


